{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2.2: The Quest For A Better Network\n",
    "\n",
    "In this assignment you will build a monster network to solve Tiny ImageNet image classification.\n",
    "\n",
    "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +20% for describing your iteration path in a report below.\n",
    "* +20% for building a network that gets above 20% accuracy\n",
    "* +10% for beating each of these milestones on __TEST__ dataset:\n",
    "    * 25% (50% points)\n",
    "    * 30% (60% points)\n",
    "    * 32.5% (70% points)\n",
    "    * 35% (80% points)\n",
    "    * 37.5% (90% points)\n",
    "    * 40% (full points)\n",
    "    \n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 40%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the anytask atttachments). After that, you can use whatever you want.\n",
    "* you __can't__ do anything with validation data apart from running the evaluation procedure. Please, split train images on train and validation parts\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "   * You should certainly use adaptive optimizers\n",
    "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.ImageFolder(root=path_to_tiny_imagenet, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import PIL\n",
    "\n",
    "torch.manual_seed(239)\n",
    "np.random.seed(239)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_simple = transform_train = transforms.Compose([\n",
    "   torchvision.transforms.ToTensor(),\n",
    "   transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "   torchvision.transforms.RandomHorizontalFlip(),\n",
    "   torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "   torchvision.transforms.ToTensor(),\n",
    "   transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "from tiny_img import download_tinyImg200\n",
    "data_path = '.'\n",
    "download_tinyImg200(data_path)\n",
    "dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform_train)\n",
    "print(len(dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to copypaste code from seminar03 as a basic template for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequential_nn():\n",
    "    fst_nn = nn.Sequential()\n",
    "\n",
    "    fst_nn.add_module('conv1_1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1, bias=False))\n",
    "    fst_nn.add_module('bn1_1', nn.BatchNorm2d(num_features=32))\n",
    "    fst_nn.add_module('lrelu1_1', nn.LeakyReLU())\n",
    "\n",
    "    fst_nn.add_module('conv1_2', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=False))    \n",
    "    fst_nn.add_module('bn1_2', nn.BatchNorm2d(num_features=32))\n",
    "    fst_nn.add_module('lrelu1_2', nn.LeakyReLU())\n",
    "    \n",
    "    fst_nn.add_module('maxpool1', nn.MaxPool2d(2))\n",
    "    fst_nn.add_module('dropout1', nn.Dropout(p=0.3))\n",
    "    \n",
    "    ########################################################################\n",
    "    \n",
    "    fst_nn.add_module('conv2_1', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, bias=False))\n",
    "    fst_nn.add_module('bn2_1', nn.BatchNorm2d(num_features=64))\n",
    "    fst_nn.add_module('lrelu2_1', nn.LeakyReLU())\n",
    "    \n",
    "    fst_nn.add_module('conv2_2', nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=2, dilation=2, bias=False))\n",
    "    fst_nn.add_module('bn2_2', nn.BatchNorm2d(num_features=64))\n",
    "    fst_nn.add_module('lrelu2_2', nn.LeakyReLU())\n",
    "    \n",
    "    fst_nn.add_module('maxpool2', nn.MaxPool2d(2))\n",
    "    fst_nn.add_module('dropout2', nn.Dropout(p=0.3))\n",
    "    \n",
    "    ########################################################################\n",
    "    \n",
    "    fst_nn.add_module('conv3_1', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, bias=False))\n",
    "    fst_nn.add_module('bn3_1', nn.BatchNorm2d(num_features=128))\n",
    "    fst_nn.add_module('lrelu3_1', nn.LeakyReLU())\n",
    "    \n",
    "    fst_nn.add_module('conv3_2', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=False))\n",
    "    fst_nn.add_module('bn3_2', nn.BatchNorm2d(num_features=128))\n",
    "    fst_nn.add_module('lrelu3_2', nn.LeakyReLU())\n",
    "    \n",
    "    fst_nn.add_module('maxpool3', nn.MaxPool2d(2))\n",
    "    fst_nn.add_module('dropout3', nn.Dropout(p=0.3))\n",
    "    \n",
    "    ########################################################################\n",
    "    \n",
    "    fst_nn.add_module('conv4_1', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, bias=False))\n",
    "    fst_nn.add_module('bn4_1', nn.BatchNorm2d(num_features=256))\n",
    "    fst_nn.add_module('lrelu4_1', nn.LeakyReLU())\n",
    "    \n",
    "    fst_nn.add_module('conv4_2', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, bias=False))\n",
    "    fst_nn.add_module('bn4_2', nn.BatchNorm2d(num_features=512))\n",
    "    fst_nn.add_module('lrelu4_2', nn.LeakyReLU())\n",
    "    \n",
    "    fst_nn.add_module('dropout4', nn.Dropout(p=0.3))\n",
    "\n",
    "    ########################################################################\n",
    "    \n",
    "    fst_nn.add_module('flatten', Flatten())\n",
    "    fst_nn.add_module('dense1', nn.Linear(in_features=32768, out_features=2048))\n",
    "    fst_nn.add_module('relu_dense', nn.ReLU())\n",
    "    fst_nn.add_module('dense2', nn.Linear(in_features=2048, out_features=1024))\n",
    "    fst_nn.add_module('relu_dense2', nn.ReLU())\n",
    "    fst_nn.add_module('dropout_dense2', nn.Dropout(p=0.3))\n",
    "    fst_nn.add_module('dense2_logits', nn.Linear(in_features=1024, out_features=200))\n",
    "    \n",
    "    return fst_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_nn = build_sequential_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fst_nn.load_state_dict(torch.load('fst_nn_v2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch, model):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()\n",
    "    y_batch = Variable(torch.LongTensor(y_batch)).cuda()\n",
    "    logits = model.cuda()(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(fst_nn.parameters(), lr=1e-4)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50 took 138.362s\n",
      "  training loss (in-iteration): \t4.756572\n",
      "  validation accuracy: \t\t\t5.21 %\n",
      "Model saved\n",
      "Epoch 2 of 50 took 137.237s\n",
      "  training loss (in-iteration): \t4.080317\n",
      "  validation accuracy: \t\t\t8.02 %\n",
      "Model saved\n",
      "Epoch 3 of 50 took 137.226s\n",
      "  training loss (in-iteration): \t3.743934\n",
      "  validation accuracy: \t\t\t14.03 %\n",
      "Model saved\n",
      "Epoch 4 of 50 took 137.203s\n",
      "  training loss (in-iteration): \t3.524559\n",
      "  validation accuracy: \t\t\t15.46 %\n",
      "Model saved\n",
      "Epoch 5 of 50 took 137.250s\n",
      "  training loss (in-iteration): \t3.354646\n",
      "  validation accuracy: \t\t\t20.08 %\n",
      "Model saved\n",
      "Epoch 6 of 50 took 137.306s\n",
      "  training loss (in-iteration): \t3.214243\n",
      "  validation accuracy: \t\t\t21.54 %\n",
      "Model saved\n",
      "Epoch 7 of 50 took 137.594s\n",
      "  training loss (in-iteration): \t3.093372\n",
      "  validation accuracy: \t\t\t22.32 %\n",
      "Model saved\n",
      "Epoch 8 of 50 took 138.513s\n",
      "  training loss (in-iteration): \t2.986943\n",
      "  validation accuracy: \t\t\t25.78 %\n",
      "Model saved\n",
      "Epoch 9 of 50 took 137.611s\n",
      "  training loss (in-iteration): \t2.881769\n",
      "  validation accuracy: \t\t\t27.85 %\n",
      "Model saved\n",
      "Epoch 10 of 50 took 137.162s\n",
      "  training loss (in-iteration): \t2.797214\n",
      "  validation accuracy: \t\t\t28.67 %\n",
      "Model saved\n",
      "Epoch 11 of 50 took 137.133s\n",
      "  training loss (in-iteration): \t2.712390\n",
      "  validation accuracy: \t\t\t31.36 %\n",
      "Model saved\n",
      "Epoch 12 of 50 took 137.273s\n",
      "  training loss (in-iteration): \t2.635187\n",
      "  validation accuracy: \t\t\t30.34 %\n",
      "Epoch 13 of 50 took 137.222s\n",
      "  training loss (in-iteration): \t2.555563\n",
      "  validation accuracy: \t\t\t33.17 %\n",
      "Model saved\n",
      "Epoch 14 of 50 took 138.260s\n",
      "  training loss (in-iteration): \t2.489603\n",
      "  validation accuracy: \t\t\t33.29 %\n",
      "Model saved\n",
      "Epoch 15 of 50 took 138.385s\n",
      "  training loss (in-iteration): \t2.427888\n",
      "  validation accuracy: \t\t\t33.22 %\n",
      "Epoch 16 of 50 took 137.508s\n",
      "  training loss (in-iteration): \t2.367088\n",
      "  validation accuracy: \t\t\t34.33 %\n",
      "Model saved\n",
      "Epoch 17 of 50 took 137.004s\n",
      "  training loss (in-iteration): \t2.303217\n",
      "  validation accuracy: \t\t\t34.34 %\n",
      "Model saved\n",
      "Epoch 18 of 50 took 137.000s\n",
      "  training loss (in-iteration): \t2.246935\n",
      "  validation accuracy: \t\t\t33.95 %\n",
      "Epoch 19 of 50 took 137.014s\n",
      "  training loss (in-iteration): \t2.187918\n",
      "  validation accuracy: \t\t\t34.09 %\n",
      "Epoch 20 of 50 took 136.978s\n",
      "  training loss (in-iteration): \t2.129781\n",
      "  validation accuracy: \t\t\t35.84 %\n",
      "Model saved\n",
      "Epoch 21 of 50 took 137.000s\n",
      "  training loss (in-iteration): \t2.083106\n",
      "  validation accuracy: \t\t\t35.35 %\n",
      "Epoch 22 of 50 took 137.086s\n",
      "  training loss (in-iteration): \t2.024171\n",
      "  validation accuracy: \t\t\t36.20 %\n",
      "Model saved\n",
      "Epoch 23 of 50 took 137.180s\n",
      "  training loss (in-iteration): \t1.977465\n",
      "  validation accuracy: \t\t\t35.66 %\n",
      "Epoch 24 of 50 took 137.116s\n",
      "  training loss (in-iteration): \t1.934958\n",
      "  validation accuracy: \t\t\t36.63 %\n",
      "Model saved\n",
      "Epoch 25 of 50 took 137.191s\n",
      "  training loss (in-iteration): \t1.887041\n",
      "  validation accuracy: \t\t\t37.02 %\n",
      "Model saved\n",
      "Epoch 26 of 50 took 137.628s\n",
      "  training loss (in-iteration): \t1.841566\n",
      "  validation accuracy: \t\t\t37.64 %\n",
      "Model saved\n",
      "Epoch 27 of 50 took 137.655s\n",
      "  training loss (in-iteration): \t1.801274\n",
      "  validation accuracy: \t\t\t37.31 %\n",
      "Epoch 28 of 50 took 137.626s\n",
      "  training loss (in-iteration): \t1.754082\n",
      "  validation accuracy: \t\t\t37.11 %\n",
      "Epoch 29 of 50 took 137.648s\n",
      "  training loss (in-iteration): \t1.711526\n",
      "  validation accuracy: \t\t\t37.10 %\n",
      "Epoch 30 of 50 took 137.639s\n",
      "  training loss (in-iteration): \t1.671417\n",
      "  validation accuracy: \t\t\t38.20 %\n",
      "Model saved\n",
      "Epoch 31 of 50 took 137.667s\n",
      "  training loss (in-iteration): \t1.633090\n",
      "  validation accuracy: \t\t\t37.43 %\n",
      "Epoch 32 of 50 took 137.641s\n",
      "  training loss (in-iteration): \t1.601072\n",
      "  validation accuracy: \t\t\t36.94 %\n",
      "Epoch 33 of 50 took 137.685s\n",
      "  training loss (in-iteration): \t1.558085\n",
      "  validation accuracy: \t\t\t37.31 %\n",
      "Epoch 34 of 50 took 137.638s\n",
      "  training loss (in-iteration): \t1.520504\n",
      "  validation accuracy: \t\t\t38.23 %\n",
      "Model saved\n",
      "Epoch 35 of 50 took 137.681s\n",
      "  training loss (in-iteration): \t1.483881\n",
      "  validation accuracy: \t\t\t38.67 %\n",
      "Model saved\n",
      "Epoch 36 of 50 took 137.627s\n",
      "  training loss (in-iteration): \t1.453110\n",
      "  validation accuracy: \t\t\t37.22 %\n",
      "Epoch 37 of 50 took 137.722s\n",
      "  training loss (in-iteration): \t1.411601\n",
      "  validation accuracy: \t\t\t38.11 %\n",
      "Epoch 38 of 50 took 137.611s\n",
      "  training loss (in-iteration): \t1.383533\n",
      "  validation accuracy: \t\t\t37.69 %\n",
      "Epoch 39 of 50 took 137.579s\n",
      "  training loss (in-iteration): \t1.352148\n",
      "  validation accuracy: \t\t\t37.38 %\n",
      "Epoch 40 of 50 took 137.648s\n",
      "  training loss (in-iteration): \t1.319615\n",
      "  validation accuracy: \t\t\t37.65 %\n",
      "Epoch 41 of 50 took 137.640s\n",
      "  training loss (in-iteration): \t1.285726\n",
      "  validation accuracy: \t\t\t38.55 %\n",
      "Epoch 42 of 50 took 137.704s\n",
      "  training loss (in-iteration): \t1.259659\n",
      "  validation accuracy: \t\t\t38.08 %\n",
      "Epoch 43 of 50 took 137.588s\n",
      "  training loss (in-iteration): \t1.229504\n",
      "  validation accuracy: \t\t\t38.40 %\n",
      "Epoch 44 of 50 took 137.680s\n",
      "  training loss (in-iteration): \t1.206113\n",
      "  validation accuracy: \t\t\t38.13 %\n",
      "Epoch 45 of 50 took 137.613s\n",
      "  training loss (in-iteration): \t1.178376\n",
      "  validation accuracy: \t\t\t37.84 %\n",
      "Epoch 46 of 50 took 137.613s\n",
      "  training loss (in-iteration): \t1.151715\n",
      "  validation accuracy: \t\t\t37.76 %\n",
      "Epoch 47 of 50 took 137.662s\n",
      "  training loss (in-iteration): \t1.122342\n",
      "  validation accuracy: \t\t\t38.17 %\n",
      "Epoch 48 of 50 took 137.643s\n",
      "  training loss (in-iteration): \t1.098968\n",
      "  validation accuracy: \t\t\t37.27 %\n",
      "Epoch 49 of 50 took 137.685s\n",
      "  training loss (in-iteration): \t1.074497\n",
      "  validation accuracy: \t\t\t38.05 %\n",
      "Epoch 50 of 50 took 137.567s\n",
      "  training loss (in-iteration): \t1.070037\n",
      "  validation accuracy: \t\t\t38.02 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_epochs = 50 # total amount of full passes over training data\n",
    "\n",
    "import time\n",
    "max_acc = 0.\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    fst_nn.train(True) # enable dropout / batch_norm training behavior\n",
    "    for (X_batch, y_batch) in train_batch_gen:\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch, fst_nn)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "    \n",
    "    fst_nn.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_batch_gen:\n",
    "        logits = fst_nn(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "    val_acc = np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        val_acc))\n",
    "    if val_acc > max_acc:\n",
    "        torch.save(fst_nn.state_dict(), 'fst_nn_v22.pt')\n",
    "        max_acc = val_acc\n",
    "        print('Model saved')\n",
    "        \n",
    "    # lr decay\n",
    "    if epoch + 1 % 10 == 0:\n",
    "        for g in opt.param_groups:\n",
    "            g['lr'] = max(g['lr']/5, 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything is done, please calculate accuracy on `tiny-imagenet-200/val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.ImageFolder('tiny-imagenet-200/val_reordered/', transform=transforms_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_gen = torch.utils.data.DataLoader(test_data, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "test_net = build_sequential_nn()\n",
    "test_net.load_state_dict(torch.load('fst_nn_v22.pt'))\n",
    "test_net.eval()\n",
    "test_net.cuda()\n",
    "for X_batch, y_batch in test_batch_gen:\n",
    "        logits = test_net(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        test_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35739999999999994"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = np.mean(test_acc)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t35.74 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 40:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 35:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 30:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 25:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.83125000000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc = []\n",
    "for X_batch, y_batch in train_batch_gen:\n",
    "        logits = test_net(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        train_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "train_accuracy = np.mean(train_acc) * 100\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Report\n",
    "\n",
    "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
    "* the idea;\n",
    "* brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method and, again, why?\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "\n",
    "There is no need to write strict mathematical proofs (unless you want to).\n",
    " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
    " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
    " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `Sergey Gorbatyuk`, and here's my story\n",
    "\n",
    "A long time ago in a galaxy far far away, when it was still more than an hour before the deadline, i got an idea: actually just build a conv simple sequentioal conv net, and if i have more time, try to build resnet.\n",
    "\n",
    "##### I gonna build a neural network, that\n",
    "First replicates architecture form the seminar. Then I gonna try some things like more packs of conv-pool-relu-bn-dropout,\n",
    "normalizing inputs and early stopping.\n",
    "\n",
    "How could i be so naive?!\n",
    "\n",
    "##### One day, with no signs of warning,\n",
    "This thing has finally converged and\n",
    "i got score like 0.5%. That gave me a thought that this thing learned like nothing, and after some time i realized that the problem is \n",
    "that default learning rate in Adam is too big to train this one. Moreover, I understood that 3 conv layers with other stuff is not enough \n",
    "cause receptive field is still very small. I trained it with less lr and more convs, and got significially better score like 25%.\n",
    "\n",
    "##### Finally, after ~30  iterations, np.float('+inf') mugs of coffee\n",
    "I got the final score of 35% on test set. Not the best one, but i believed that i would reach the desired 40% with convs only. Actually this day I also realized that the deadline was on past midnight, not on the coming one, and got upset even more:(\n",
    "\n",
    "The final architecture was 4x2 packs of conv3-bn-LReLU separated by maxpool2-dropout. After flattening there were three dense layers with ReLU and dropouts. The training procedure was optimized by Adam optimizer and here I confess that I did not try another one, because I knew that Adam performs better in average, and did not want to spend precious time making experiments with that. I intermeshed lr decay manually, because for some reason it is quite hard to do in pytorch, and I did data augumentation.\n",
    "\n",
    "That, having wasted ____ [minutes, hours or days] of my life training, got\n",
    "\n",
    "* accuracy on training: 74,83%\n",
    "* accuracy on validation: 38,67%\n",
    "* accuracy on test: 35,74%\n",
    "\n",
    "I regret that spent not enough time doing that, and had no chance to try resnet. But still, i am sending this one, but will try to do something better ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
